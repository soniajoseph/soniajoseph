---
title: "Favorite Papers in Computational Neuroscience"
excerpt: "A running record of my favorite papers in computational neuroscience."
categories: [computational neuroscience]
tags: [notes, computational neuroscience, neuroscience, literature review, resources]
header:
  teaser: assets/images/posts/three-dimensions-network-models.png
toc: false
---

*From most to least recent, in progress.*

I've compiled computational neuroscience papers, perspectives, and reviews for their impact on my thinking and their generality. This list is not comprehensive by any means, and if you don't see a paper on the list, it does not mean the paper did not shape my thinking. 

**Bassett, D. S., Zurn, P., & Gold, J. I. (2018). On the nature and use of models in network neuroscience. Nature Reviews Neuroscience, 19(9), 566–578. doi:10.1038/s41583-018-0038-8.** Link [here](https://www.nature.com/articles/s41583-018-0038-8).

![](/assets/images/posts/three-dimensions-network-models.png =100x)

{% include figure image_path="/assets/images/posts/three-dimensions-network-models.png" %}

This paper is super clarifying. One point of confusion in neuroscience is clearly defining the model's purpose, which determines the model's level of abstraction. Especially in a field so young and quickly growing, researchers must have a unified framework grounded in the [philosophy of modeling](https://plato.stanford.edu/entries/models-science/). In this review Bassett, Zurn & Gold clearly provide a clear "cube-like" scaffolding for modeling with three axes: *data representation vs first-principles based, structural realism vs functional phenomenology*, and *elementary descriptions vs coarse-grained approximations*. This paper also touches upon fascinating concepts like graph-based meta-modeling using its three-axis framework.

**Yamins, D., DiCarlo, J. Using goal-driven deep learning models to understand sensory cortex. Nat Neurosci 19, 356–365 (2016). https://doi.org/10.1038/nn.4244.** Link [here](https://www.nature.com/articles/nn.4244).
